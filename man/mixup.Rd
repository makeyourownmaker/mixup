% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mixup.R
\docType{package}
\name{mixup}
\alias{mixup}
\alias{mixup-package}
\title{mixup Function}
\usage{
mixup(x1, y1, alpha = 1, concat = FALSE, batch_size = NULL)
}
\arguments{
\item{x1}{Original features}

\item{y1}{Original labels}

\item{alpha}{Hyperparameter specifying strength of interpolation}

\item{concat}{Concatenate mixup data with original}

\item{batch_size}{How many mixup values to produce}
}
\value{
A list containing interpolated x and y values and optionally the original values
}
\description{
This function enlarges training sets using linear interpolations 
of features and associated labels as described in 
https://arxiv.org/abs/1710.09412.

Mixup constructs additional training examples:
}
\details{
The x1 and y1 parameters must be numeric and must have equal 
numbers of examples.  Non-finite values are not permitted.
Factors should be one-hot encoded.

For now, only binary classification is supported.  Meaning y1 must contain 
only numeric 0 and 1 values.

Alpha values must be greater than or equal to zero.  Alpha equal to zero
specifies no interpolation.

The mixup function returns a two-element list containing interpolated x 
and y values.  Optionally, the original values can be concatenated with the
new values.

\eqn{x' = \lambda * x_i + (1 - \lambda) * x_j, \textrm{where} x_i, x_j} are raw input vectors
\eqn{y' = \lambda * y_i + (1 - \lambda) * y_j, \textrm{where} y_i, y_j} are one-hot label encodings

\eqn{(x_i, y_i)} and \eqn{(x_j ,y_j)} are two examples drawn at random from the training 
data, and \eqn{\lambda \in [0, 1]} with \eqn{\lambda ∼ \textrm{Beta}(\alpha, \alpha)} for \eqn{\alpha \in (0, \infty)}.
The mixup hyper-parameter α controls the strength of interpolation between 
feature-target pairs.
}
\examples{
mtcars.mix <- mixup(mtcars[, -9], mtcars$am)
}
